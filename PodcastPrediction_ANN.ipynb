{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tejassorte/Python-Projects/blob/master/PodcastPrediction_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZvpcQG1Flzn",
        "outputId": "5f019f24-2bfd-47de-d2d0-ce98d97ab2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Define custom RMSE metric\n",
        "def rmse(y_true, y_pred):\n",
        "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"train.csv\")  # Replace with your actual file path\n",
        "\n",
        "# Check for NaNs in dataset\n",
        "print(\"NaNs before handling:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Fill missing values in 'Episode_Length_minutes' and 'Guest_Popularity_percentage'\n",
        "df['Episode_Length_minutes'].fillna(df['Episode_Length_minutes'].mean(), inplace=True)\n",
        "df['Guest_Popularity_percentage'].fillna(df['Guest_Popularity_percentage'].mean(), inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(['Listening_Time_minutes', 'Episode_Title', 'id', 'Podcast_Name'], axis=1) # Dropping unnecessary columns\n",
        "y = df['Listening_Time_minutes']\n",
        "\n",
        "# Convert numerical columns to float32\n",
        "for col in ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']:\n",
        "    X[col] = X[col].astype('float32')\n",
        "y = y.astype('float32')\n",
        "\n",
        "# Check for NaNs after handling\n",
        "print(\"\\nNaNs after handling:\")\n",
        "print(X.isnull().sum())\n",
        "print(np.any(X.isnull()))\n",
        "\n",
        "# Define categorical and numerical columns\n",
        "categorical_cols = ['Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']\n",
        "numerical_cols = ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numerical_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Transform features\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# Build model with a lower learning rate\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=X_train_processed.shape[1], activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model with custom RMSE\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='mean_squared_error',\n",
        "              metrics=[rmse])\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train model with RMSE metric\n",
        "history = model.fit(\n",
        "    X_train_processed, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=8,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXRcTaO_psOI",
        "outputId": "e57c590f-9daf-4e55-dbe5-3c4d80f97d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaNs before handling:\n",
            "id                                  0\n",
            "Podcast_Name                        0\n",
            "Episode_Title                       0\n",
            "Episode_Length_minutes          87093\n",
            "Genre                               0\n",
            "Host_Popularity_percentage          0\n",
            "Publication_Day                     0\n",
            "Publication_Time                    0\n",
            "Guest_Popularity_percentage    146030\n",
            "Number_of_Ads                       0\n",
            "Episode_Sentiment                   0\n",
            "Listening_Time_minutes              0\n",
            "dtype: int64\n",
            "\n",
            "NaNs after handling:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2-2227020731.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Episode_Length_minutes'].fillna(df['Episode_Length_minutes'].mean(), inplace=True)\n",
            "/tmp/ipython-input-2-2227020731.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Guest_Popularity_percentage'].fillna(df['Guest_Popularity_percentage'].mean(), inplace=True)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode_Length_minutes         0\n",
            "Genre                          0\n",
            "Host_Popularity_percentage     0\n",
            "Publication_Day                0\n",
            "Publication_Time               0\n",
            "Guest_Popularity_percentage    0\n",
            "Number_of_Ads                  0\n",
            "Episode_Sentiment              0\n",
            "dtype: int64\n",
            "False\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - loss: 317.7998 - rmse: 15.4598 - val_loss: 176.7461 - val_rmse: 12.5647\n",
            "Epoch 2/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 3ms/step - loss: 197.1338 - rmse: 13.2668 - val_loss: 175.9568 - val_rmse: 12.5325\n",
            "Epoch 3/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 3ms/step - loss: 193.3681 - rmse: 13.1425 - val_loss: 178.2298 - val_rmse: 12.6146\n",
            "Epoch 4/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 3ms/step - loss: 191.1761 - rmse: 13.0628 - val_loss: 176.6759 - val_rmse: 12.5581\n",
            "Epoch 5/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 3ms/step - loss: 188.5502 - rmse: 12.9748 - val_loss: 175.6422 - val_rmse: 12.5203\n",
            "Epoch 6/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 3ms/step - loss: 185.8984 - rmse: 12.8804 - val_loss: 182.3841 - val_rmse: 12.7633\n",
            "Epoch 7/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3ms/step - loss: 183.6868 - rmse: 12.8050 - val_loss: 179.1120 - val_rmse: 12.6453\n",
            "Epoch 8/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 3ms/step - loss: 181.7565 - rmse: 12.7306 - val_loss: 198.6970 - val_rmse: 13.3283\n",
            "Epoch 9/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 3ms/step - loss: 180.2327 - rmse: 12.6788 - val_loss: 198.5412 - val_rmse: 13.3192\n",
            "Epoch 10/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 3ms/step - loss: 179.7883 - rmse: 12.6648 - val_loss: 198.5456 - val_rmse: 13.3182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define custom RMSE metric\n",
        "def rmse(y_true, y_pred):\n",
        "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=X_train_processed.shape[1], activation='relu'),  # More neurons\n",
        "    BatchNormalization(),  # Stabilize learning\n",
        "    Dropout(0.3),  # Prevent overfitting\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile with custom RMSE metric\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[rmse])\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    X_train_processed, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=8,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwwS9rEktRPU",
        "outputId": "815f13d5-4ddf-49e0-ccef-8a2238d7891a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 4ms/step - loss: 572.3119 - rmse: 21.1071 - val_loss: 182.2647 - val_rmse: 12.7892\n",
            "Epoch 2/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 3ms/step - loss: 236.7978 - rmse: 14.6627 - val_loss: 177.8394 - val_rmse: 12.6083\n",
            "Epoch 3/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 3ms/step - loss: 215.9993 - rmse: 13.9756 - val_loss: 179.1746 - val_rmse: 12.6633\n",
            "Epoch 4/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 4ms/step - loss: 207.4147 - rmse: 13.6873 - val_loss: 177.4847 - val_rmse: 12.5927\n",
            "Epoch 5/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 3ms/step - loss: 202.1378 - rmse: 13.5102 - val_loss: 177.5293 - val_rmse: 12.5837\n",
            "Epoch 6/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 3ms/step - loss: 198.3818 - rmse: 13.3629 - val_loss: 176.3110 - val_rmse: 12.5418\n",
            "Epoch 7/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 4ms/step - loss: 195.7579 - rmse: 13.2624 - val_loss: 176.2505 - val_rmse: 12.5363\n",
            "Epoch 8/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 4ms/step - loss: 193.3517 - rmse: 13.1725 - val_loss: 178.5486 - val_rmse: 12.6112\n",
            "Epoch 9/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 3ms/step - loss: 189.9149 - rmse: 13.0599 - val_loss: 178.2204 - val_rmse: 12.6098\n",
            "Epoch 10/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 4ms/step - loss: 190.2913 - rmse: 13.0699 - val_loss: 179.7476 - val_rmse: 12.6178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Define custom RMSE metric\n",
        "def rmse(y_true, y_pred):\n",
        "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        "\n",
        "# Build an improved model\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=X_train_processed.shape[1], activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[rmse])\n",
        "\n",
        "# Callbacks for better training\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', patience=15, restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.2, patience=7, min_lr=1e-6\n",
        ")\n",
        "\n",
        "# Fit the model with more epochs and callbacks\n",
        "history = model.fit(\n",
        "    X_train_processed, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=20,  # More epochs for better convergence\n",
        "    batch_size=8,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qren-Rwpnvtn",
        "outputId": "a6141877-757c-44d9-d60e-d4df32634473"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 4ms/step - loss: 308.7704 - rmse: 16.0134 - val_loss: 198.3238 - val_rmse: 13.3898 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 4ms/step - loss: 203.0337 - rmse: 13.5292 - val_loss: 190.3497 - val_rmse: 13.0235 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 4ms/step - loss: 196.3224 - rmse: 13.2832 - val_loss: 184.2876 - val_rmse: 12.7995 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 4ms/step - loss: 193.5843 - rmse: 13.1928 - val_loss: 181.5809 - val_rmse: 12.7090 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 4ms/step - loss: 191.7590 - rmse: 13.1159 - val_loss: 176.7747 - val_rmse: 12.5606 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 4ms/step - loss: 190.1466 - rmse: 13.0629 - val_loss: 216.7091 - val_rmse: 13.5453 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 4ms/step - loss: 189.8449 - rmse: 13.0526 - val_loss: 7903.6475 - val_rmse: 13.4452 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 4ms/step - loss: 189.3491 - rmse: 13.0289 - val_loss: 186.5232 - val_rmse: 12.6979 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 4ms/step - loss: 187.6082 - rmse: 12.9713 - val_loss: 179.0471 - val_rmse: 12.6278 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 4ms/step - loss: 188.3446 - rmse: 12.9972 - val_loss: 2112.5891 - val_rmse: 13.9788 - learning_rate: 5.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 4ms/step - loss: 187.0446 - rmse: 12.9480 - val_loss: 52931.7891 - val_rmse: 18.1465 - learning_rate: 5.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 4ms/step - loss: 185.7978 - rmse: 12.9054 - val_loss: 571.6208 - val_rmse: 13.2627 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 4ms/step - loss: 183.1864 - rmse: 12.8118 - val_loss: 720.5707 - val_rmse: 13.2651 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 4ms/step - loss: 183.0189 - rmse: 12.7965 - val_loss: 1551.8934 - val_rmse: 16.4365 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 4ms/step - loss: 184.1729 - rmse: 12.8374 - val_loss: 335.1044 - val_rmse: 12.8875 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 4ms/step - loss: 182.8890 - rmse: 12.7940 - val_loss: 4234.5747 - val_rmse: 13.7031 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 4ms/step - loss: 181.9611 - rmse: 12.7563 - val_loss: 841.7350 - val_rmse: 13.2198 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 4ms/step - loss: 182.4148 - rmse: 12.7811 - val_loss: 1227.4143 - val_rmse: 14.9488 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 4ms/step - loss: 181.8598 - rmse: 12.7547 - val_loss: 2210.0369 - val_rmse: 13.9834 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 4ms/step - loss: 181.7886 - rmse: 12.7527 - val_loss: 1111.4464 - val_rmse: 15.2742 - learning_rate: 2.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P-VeXRQxDcvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Define custom RMSE metric\n",
        "def rmse(y_true, y_pred):\n",
        "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"train.csv\")  # Replace with your actual file path\n",
        "\n",
        "# Check for NaNs in dataset\n",
        "print(\"NaNs before handling:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Fill missing values in 'Episode_Length_minutes' and 'Guest_Popularity_percentage'\n",
        "df['Episode_Length_minutes'].fillna(df['Episode_Length_minutes'].mean(), inplace=True)\n",
        "df['Guest_Popularity_percentage'].fillna(df['Guest_Popularity_percentage'].mean(), inplace=True)\n",
        "\n",
        "# Drop rows with NaNs in target (if any, though info() shows none)\n",
        "df.dropna(subset=['Listening_Time_minutes'], inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(['Listening_Time_minutes', 'Episode_Title', 'id', 'Podcast_Name'], axis=1) # Dropping unnecessary columns\n",
        "y = df['Listening_Time_minutes']\n",
        "\n",
        "# Convert numerical columns to float32\n",
        "for col in ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']:\n",
        "    X[col] = X[col].astype('float32')\n",
        "y = y.astype('float32')\n",
        "\n",
        "# Check for NaNs after handling\n",
        "print(\"\\nNaNs after handling:\")\n",
        "print(X.isnull().sum())\n",
        "print(np.any(X.isnull()))\n",
        "\n",
        "# Define categorical and numerical columns\n",
        "categorical_cols = ['Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']\n",
        "numerical_cols = ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numerical_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Transform features\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# Build model with a lower learning rate\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=X_train_processed.shape[1], activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model with custom RMSE\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='mean_squared_error',\n",
        "              metrics=[rmse])\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train model with RMSE metric\n",
        "history = model.fit(\n",
        "    X_train_processed, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=8,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHg9cW_LEgpq",
        "outputId": "db35b83e-05f9-45db-e4b1-bcc08157d5da"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaNs before handling:\n",
            "id                                  0\n",
            "Podcast_Name                        0\n",
            "Episode_Title                       0\n",
            "Episode_Length_minutes          87093\n",
            "Genre                               0\n",
            "Host_Popularity_percentage          0\n",
            "Publication_Day                     0\n",
            "Publication_Time                    0\n",
            "Guest_Popularity_percentage    146030\n",
            "Number_of_Ads                       0\n",
            "Episode_Sentiment                   0\n",
            "Listening_Time_minutes              0\n",
            "dtype: int64\n",
            "\n",
            "NaNs after handling:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-9-2227020731.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Episode_Length_minutes'].fillna(df['Episode_Length_minutes'].mean(), inplace=True)\n",
            "/tmp/ipython-input-9-2227020731.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Guest_Popularity_percentage'].fillna(df['Guest_Popularity_percentage'].mean(), inplace=True)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode_Length_minutes         0\n",
            "Genre                          0\n",
            "Host_Popularity_percentage     0\n",
            "Publication_Day                0\n",
            "Publication_Time               0\n",
            "Guest_Popularity_percentage    0\n",
            "Number_of_Ads                  0\n",
            "Episode_Sentiment              0\n",
            "dtype: int64\n",
            "False\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 3ms/step - loss: 318.2057 - rmse: 15.4962 - val_loss: 177.4747 - val_rmse: 12.5924\n",
            "Epoch 2/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 3ms/step - loss: 194.9425 - rmse: 13.1970 - val_loss: 182.2597 - val_rmse: 12.7622\n",
            "Epoch 3/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 3ms/step - loss: 191.8946 - rmse: 13.0989 - val_loss: 179.3392 - val_rmse: 12.6556\n",
            "Epoch 4/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 3ms/step - loss: 189.8860 - rmse: 13.0121 - val_loss: 179.1548 - val_rmse: 12.6468\n",
            "Epoch 5/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3ms/step - loss: 186.3464 - rmse: 12.9037 - val_loss: 189.2628 - val_rmse: 13.0025\n",
            "Epoch 6/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 3ms/step - loss: 184.3038 - rmse: 12.8220 - val_loss: 196.6060 - val_rmse: 13.2564\n",
            "Epoch 7/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3ms/step - loss: 180.6592 - rmse: 12.6963 - val_loss: 218.9655 - val_rmse: 14.0052\n",
            "Epoch 8/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 3ms/step - loss: 181.0077 - rmse: 12.7144 - val_loss: 237.1926 - val_rmse: 14.5920\n",
            "Epoch 9/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 3ms/step - loss: 180.6214 - rmse: 12.6896 - val_loss: 229.3096 - val_rmse: 14.3378\n",
            "Epoch 10/10\n",
            "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 3ms/step - loss: 178.5893 - rmse: 12.6136 - val_loss: 226.4785 - val_rmse: 14.2454\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}